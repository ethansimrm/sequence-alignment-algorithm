"""
Provide code and solution for Application 4
"""

DESKTOP = False

import math
import random
import urllib2

if DESKTOP:
    import matplotlib.pyplot as plt
    import alg_project4_solution as student
else:
    import simpleplot
    import user48_ZImNlQzYEq_57 as student
    

# URLs for data files
PAM50_URL = "http://storage.googleapis.com/codeskulptor-alg/alg_PAM50.txt"
HUMAN_EYELESS_URL = "http://storage.googleapis.com/codeskulptor-alg/alg_HumanEyelessProtein.txt"
FRUITFLY_EYELESS_URL = "http://storage.googleapis.com/codeskulptor-alg/alg_FruitflyEyelessProtein.txt"
CONSENSUS_PAX_URL = "http://storage.googleapis.com/codeskulptor-alg/alg_ConsensusPAXDomain.txt"
WORD_LIST_URL = "http://storage.googleapis.com/codeskulptor-assets/assets_scrabble_words3.txt"

###############################################
# provided code

def read_scoring_matrix(filename):
    """
    Read a scoring matrix from the file named filename.  

    Argument:
    filename -- name of file containing a scoring matrix

    Returns:
    A dictionary of dictionaries mapping X and Y characters to scores
    """
    scoring_dict = {}
    scoring_file = urllib2.urlopen(filename)
    ykeys = scoring_file.readline()
    ykeychars = ykeys.split()
    for line in scoring_file.readlines():
        vals = line.split()
        xkey = vals.pop(0)
        scoring_dict[xkey] = {}
        for ykey, val in zip(ykeychars, vals):
            scoring_dict[xkey][ykey] = int(val)
    return scoring_dict

def read_protein(filename):
    """
    Read a protein sequence from the file named filename.

    Arguments:
    filename -- name of file containing a protein sequence

    Returns:
    A string representing the protein
    """
    protein_file = urllib2.urlopen(filename)
    protein_seq = protein_file.read()
    protein_seq = protein_seq.rstrip()
    return protein_seq

def read_words(filename):
    """
    Load word list from the file named filename.

    Returns a list of strings.
    """
    # load assets
    word_file = urllib2.urlopen(filename)
    
    # read in files as string
    words = word_file.read()
    
    # template lines and solution lines list of line string
    word_list = words.split('\n')
    print "Loaded a dictionary with", len(word_list), "words"
    return word_list

###############################################
"""
Solution for Application 4
"""
#Question 1
human_prot = read_protein(HUMAN_EYELESS_URL)
fly_prot = read_protein(FRUITFLY_EYELESS_URL)
score_mat = read_scoring_matrix(PAM50_URL)
align_mat = student.compute_alignment_matrix(human_prot, fly_prot, score_mat, False)
result_q1 = student.compute_local_alignment(human_prot, fly_prot, score_mat, align_mat)
#print result_q1

#Question 2
consensus = read_protein(CONSENSUS_PAX_URL)
human_extract = result_q1[1]
fly_extract = result_q1[2]

def q2_calculator(seq_x, consensus_seq):
    """
    Strips dashes, computes global alignment, and returns percentage similarity.
    """
    counter = 0.0
    seq_x_clean = seq_x.replace("-", "")
    alignment_matrix = student.compute_alignment_matrix(seq_x_clean, consensus_seq, score_mat, True)
    global_alignment = student.compute_global_alignment(seq_x_clean, consensus_seq, score_mat, alignment_matrix)
    for char_idx in range(len(global_alignment[1])):
        if global_alignment[1][char_idx] == global_alignment[2][char_idx]:
            counter += 1
    return counter / len(global_alignment[1]) * 100

#print q2_calculator(human_extract, consensus)
#print q2_calculator(fly_extract, consensus)

#Question 3
#print len(human_extract)
#print len(fly_extract)
#
#counter = 0
#for char_idx in range(133):
#        if human_extract[char_idx] == fly_extract[char_idx]:
#            counter += 1
#print counter
#
#print (1.0 / 23) ** 125

#Question 4
import random

def generate_null_distribution(seq_x, seq_y, scoring_matrix, num_trials):
    """
    This function should return a dictionary scoring_distribution that 
    represents an un-normalized distribution generated by repeatedly 
    permuting seq_y and calculating the maximum score of its local alignment
    with seq_x. How likely is it that our score was arrived at by chance?
    """
    scoring_distribution = {}
    for trial in range(num_trials):
        perm_y = list(seq_y)
        random.shuffle(perm_y)
        rand_y = ""
        for char in perm_y:
            rand_y += char
        trial_align_mat = student.compute_alignment_matrix(seq_x, rand_y, scoring_matrix, False)
        (score, dummy_1, dummy_2) = student.compute_local_alignment(seq_x, rand_y, scoring_matrix, trial_align_mat)
        if score not in scoring_distribution.keys():
            scoring_distribution[score] = 1
        else:
            scoring_distribution[score] += 1
    return scoring_distribution

#print generate_null_distribution(human_prot, fly_prot, score_mat, 1000)

scoring_dist = {85: 1, 61: 18, 51: 68, 57: 38, 87: 1, 78: 1, 54: 42, 62: 14, 56: 35, 76: 1, 71: 3, 75: 1, 55: 37, 64: 9, 74: 2, 48: 69, 49: 63, 50: 73, 72: 3, 52: 52, 40: 9, 41: 10, 58: 34, 59: 30, 43: 31, 65: 5, 70: 4, 80: 1, 42: 22, 66: 6, 67: 8, 39: 7, 60: 21, 47: 53, 68: 4, 84: 2, 45: 53, 63: 9, 44: 50, 53: 42, 69: 3, 46: 65}

def normalise(scoring_distribution):
    norm_dist = dict(scoring_distribution)
    for score in norm_dist.keys():
        norm_dist[score] = norm_dist[score] / 1000.0
    return norm_dist

normalised_dist = normalise(scoring_dist)

import simpleplot

#simpleplot.plot_bars("Maximum Scores from 1000 Local Alignments of HumanEyelessProtein and Randomised FruitflyEyelessProtein", 600, 600, 
#                     "Scores", "Fraction of Total Trials", 
#                     [normalised_dist])

#Question 5
import math

def mean(norm_distribution):
    total = 0.0
    for score in norm_distribution.keys():
        total += score * norm_distribution[score] 
    return total

q5_mean = mean(normalised_dist)

def std_dev(norm_distribution):
    total = 0.0
    for score in norm_distribution.keys():
        total += ((score - q5_mean) ** 2) * norm_distribution[score]
    return math.sqrt(total)

#print q5_mean
q5_std_dev = std_dev(normalised_dist)
#print q5_std_dev

z_score = (875 - q5_mean) / q5_std_dev
#print z_score

#Question 7
string_a = "aaa"
string_b = "ab"

q7_score_mat = student.build_scoring_matrix("abc", 2, 1, 0)
q7_align_mat = student.compute_alignment_matrix(string_a, string_b, q7_score_mat, True)
(q7_score, dummy_1, dummy_2) = student.compute_global_alignment(string_a, string_b, q7_score_mat, q7_align_mat)
print q7_score

#I think this works because we use the formulation |a| + |b| - score(a,b).
#Differences in length are already accounted for (so we exclude dash_score entirely), and identical characters
#have been counted twice, and so need to be removed twice. Non-identical characters represent one "unit" of edit
#distance each, and should be removed only once, because we implicitly choose one to be the "reference"
#and the other to be edited until it is identical to said reference.

#Question 8
word_list = read_words(WORD_LIST_URL)
def check_spelling(checked_word, dist, word_list):
    """
    Returns the set of all words within word_list that are within edit distance dist of checked_word.
    """
    ans_set = set([])
    q8_score_mat = student.build_scoring_matrix("abcdefghijklmnopqrstuvwxyz", 2, 1, 0)
    for word in word_list:
        temp_align_mat = student.compute_alignment_matrix(checked_word, word, q8_score_mat, True)
        (temp_score, dummy_1, dummy_2) = student.compute_global_alignment(checked_word, word, q8_score_mat, temp_align_mat)
        edit_dist = len(checked_word) + len(word) - temp_score
        if edit_dist <= dist:
            ans_set.add(word)
    return ans_set

print check_spelling("humble", 1, word_list)
print check_spelling("firefly", 2, word_list)
